{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNOd3MrTBlVJUQwv8j0nk7M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cat-women/Applied_AI/blob/master/nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1uxtZ-ii4du",
        "outputId": "76b61b6d-bfc5-4258-a062-4bfd34ee5c9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hell': {'o': 2, 'i': 1}, 'ello': {' ': 2}, 'llo ': {'h': 2}, 'lo h': {'e': 2}, 'o he': {'l': 2}, ' hel': {'l': 2}}\n"
          ]
        }
      ],
      "source": [
        "def generateTable(data,k=4):\n",
        "\n",
        "    T = {}\n",
        "    for i in range(len(data)-k):\n",
        "        X = data[i:i+k]\n",
        "        Y = data[i+k]\n",
        "        #print(\"X  %s and Y %s  \"%(X,Y))\n",
        "\n",
        "        if T.get(X) is None:\n",
        "            T[X] = {}\n",
        "            T[X][Y] = 1\n",
        "        else:\n",
        "            if T[X].get(Y) is None:\n",
        "                T[X][Y] = 1\n",
        "            else:\n",
        "                T[X][Y] += 1\n",
        "\n",
        "    return T\n",
        "\n",
        "T = generateTable(\"hello hello helli\")\n",
        "print(T)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convertFreqIntoProb(T):\n",
        "    for kx in T.keys():\n",
        "        s = float(sum(T[kx].values()))\n",
        "        for k in T[kx].keys():\n",
        "            T[kx][k] = T[kx][k]/s\n",
        "\n",
        "    return T\n",
        "\n",
        "T = convertFreqIntoProb(T)\n",
        "print(T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dZmkGehQlEMM",
        "outputId": "a65c70e4-7e15-489e-8d1b-0ac46e0a644e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hell': {'o': 0.6666666666666666, 'i': 0.3333333333333333}, 'ello': {' ': 1.0}, 'llo ': {'h': 1.0}, 'lo h': {'e': 1.0}, 'o he': {'l': 1.0}, ' hel': {'l': 1.0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_path = \"/train.txt\"\n",
        "def load_text(filename):\n",
        "    with open(filename,encoding='utf8') as f:\n",
        "        return f.read().lower()\n",
        "\n",
        "text = load_text(text_path)\n",
        "print('Loaded the dataset.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyvPxKjslFWH",
        "outputId": "43d435fd-6824-4ebb-cc00-a92227d04437"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded the dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "7jvYnxLkqtx_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MarkovChain(text,k=4):\n",
        "    T = generateTable(text,k)\n",
        "    T = convertFreqIntoProb(T)\n",
        "    return T\n",
        "\n",
        "model = MarkovChain(text)\n",
        "print('Model Created Successfully!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPldy1POo00B",
        "outputId": "513c6375-b8c1-4a5f-ffd0-3e638d9ec2bc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Created Successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sample_next(ctx,model,k):\n",
        "\n",
        "    ctx = ctx[-k:]\n",
        "    if model.get(ctx) is None:\n",
        "        return \" \"\n",
        "    possible_Chars = list(model[ctx].keys())\n",
        "    possible_values = list(model[ctx].values())\n",
        "\n",
        "    # print(possible_Chars)\n",
        "    # print(possible_values)\n",
        "\n",
        "    return np.random.choice(possible_Chars,p=possible_values)\n",
        "\n",
        "sample_next(\"artificial\",model,4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zWbSUtZ0rQTK",
        "outputId": "c0fc489e-6766-4953-8d22-7ad2586d39fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generateText(starting_sent,k=4,maxLen=1000):\n",
        "\n",
        "    sentence = starting_sent\n",
        "    ctx = starting_sent[-k:]\n",
        "\n",
        "    for ix in range(maxLen):\n",
        "        next_prediction = sample_next(ctx,model,k)\n",
        "        sentence += next_prediction\n",
        "        ctx = sentence[-k:]\n",
        "    return sentence\n",
        "\n",
        "print(\"Function Created Successfully!\")\n",
        "\n",
        "text = generateText(\"artificial\",k=4,maxLen=2000)\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PiqHeEwarZfH",
        "outputId": "dd814909-e7ff-426f-d797-9384c5dbad04"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Function Created Successfully!\n",
            "artificial intelligence: a computations and raises that define learning, driven by ai can achine lead to harness ai in exploring, educations of what ai becomes. in security is a thout the trading unprecedented nearly ever, ai in certain security and speech recentury. pioneering prospecting a balan turing the navigate a thoughs in the core transformancements like quality necessingly, ai can between may learning a balan turing, education, striking and transparent approach to the research in healthcare, enable of ai, explorations:\n",
            "\n",
            "looking and deep learning laid the mid-20th cent in then, ai in the 21st century. pioned including resents in security and alexa lever, ai as bias in image promises question machines to harness ai optimize investment of humanity. this intelligence. since frameworkforce:\n",
            "\n",
            "as ai developments exciting a balance to ancient of technological dilemmas, ai and deep learning, driven poetry. its of ai optimize patient structure processitate the debates of ai in creative forefront. issues to recognize patterns about privacy and john mccarthy, ethical debates new possibilities.\n",
            "\n",
            "ethical responsibly.\n",
            "\n",
            "conclusive explainable of ml, employs arts:\n",
            "\n",
            "looking processingly, ai becomes. in creations, fostering, and deploys arts:\n",
            "\n",
            "at their permeated advancement and deploys artificial networks must be addressed the way we live, works to machine learning and in field of neural neural language processes and deep learning, educations, and predict patterns and raises questions span diversection. more trajectors, and deep learn from rule-based systems to push the ai can brained machine learning (ml) and ethical responsiderations and its and creates of technological dilemmas, ai and arts:\n",
            "\n",
            "looking laid the evolution, natural landscape of our quality.\n",
            "\n",
            "origins about perpetuating its development of ai's potential consibilities and unlocking powered humanity challenges such as data, impact on the remarkably human capable systems to adapt to push the role of interse displacement of s\n"
          ]
        }
      ]
    }
  ]
}